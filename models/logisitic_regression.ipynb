{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logisitic Regression Modeling\n",
    "\n",
    "In this notebook, we iterate through a logisitic regression baseline, trying different class imbalance remedy methods. We also grid search to try and optomize the baseline's hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns; sns.set()\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from sklearn.feature_extraction import text \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, plot_confusion_matrix, roc_curve, auc, classification_report\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing X and y from `nlp_preprocessing.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lem = pickle.load(open(r'C:\\Users\\Ricky\\Desktop\\4.2 FINAL SEMESTER\\PROJECT II  Computer systems Project\\rOOT\\Preprocessing\\pickle\\X_lem.pkl', 'rb'))\n",
    "y_lem = pd.read_pickle(r'C:\\Users\\Ricky\\Desktop\\4.2 FINAL SEMESTER\\PROJECT II  Computer systems Project\\rOOT\\Preprocessing\\pickle\\y_lem.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up stop words\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split & Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_lem, y_lem, test_size=0.20, random_state=15)\n",
    "\n",
    "# using tf_idf vectorizor\n",
    "tfidf = TfidfVectorizer(stop_words= stop_words, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse matrix format with 265K stored elements\n",
    "tfidf_data_train = tfidf.fit_transform(X_train)\n",
    "tfidf_data_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Imbalance in Training Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating single df for training set\n",
    "X_train_df = pd.DataFrame(data=tfidf_data_train, index=None, columns=['tweet']) \n",
    "y_train_df = pd.DataFrame(data=y_train, index=None, columns=['label']) \n",
    "# joining them\n",
    "training = pd.concat([X_train_df, y_train_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 176317)\\t0.2391880789560643\\n  (0, 12683...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0, 122955)\\t0.25362234375833337\\n  (0, 1178...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0    (0, 176317)\\t0.2391880789560643\\n  (0, 12683...    0.0\n",
       "1    (0, 122955)\\t0.25362234375833337\\n  (0, 1178...    0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate minority and majority classes\n",
    "hate = training[training.label==1]\n",
    "not_hate = training[training.label==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2564, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37576, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_hate.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this data has a huge **class imbalance**. After running a baseline, we can try oversampling the minority class (hate speech) with SMOTE and undersampling the majority class with Tomek Links."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_baseline = LogisticRegression(penalty='l2', class_weight='balanced')\n",
    "# class_weight='balanced' actually didn't impact the score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression(solver='lbfgs', max_iter=300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ricky\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logreg_baseline.fit(tfidf_data_train, y_train)\n",
    "logreg_test_preds = logreg_baseline.predict(tfidf_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_precision = precision_score(y_test, logreg_test_preds)\n",
    "logreg_recall = recall_score(y_test, logreg_test_preds)\n",
    "logreg_f1_score = f1_score(y_test, logreg_test_preds)\n",
    "logreg_weighted_f1_score = f1_score(y_test, logreg_test_preds, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Metrics for Logistic Regression Baseline with Lemmatization Features\n",
      "Precision: 0.2199\n",
      "Recall: 0.6799\n",
      "F1 Score: 0.3324\n"
     ]
    }
   ],
   "source": [
    "# printing evaluation metrics up to 4th decimal place\n",
    "print('Testing Metrics for Logistic Regression Baseline with Lemmatization Features')\n",
    "print('Precision: {:.4}'.format(logreg_precision))\n",
    "print('Recall: {:.4}'.format(logreg_recall))\n",
    "print('F1 Score: {:.4}'.format(logreg_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dictionary with all metrics\n",
    "metric_dict = {}\n",
    "metric_dict['Baseline Logisitic Regression'] = {'precision': logreg_precision, 'recall': logreg_recall, 'f1_score': logreg_f1_score, 'weighted_f1': logreg_weighted_f1_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.5, -0.5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat = confusion_matrix(y_test, logreg_test_preds)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=['Hate Speech', 'Not Hate Speech'], yticklabels=['Hate Speech', 'Not Hate Speech'], cmap=\"Blues\")\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')\n",
    "plt.title('Logisitic Regression Baseline')\n",
    "\n",
    "# fixing matplotlib heatmap cutoff issue\n",
    "b, t = plt.ylim() # discover the values for bottom and top\n",
    "b += 0.5 # Add 0.5 to the bottom\n",
    "t -= 0.5 # Subtract 0.5 from the top\n",
    "plt.ylim(b, t) # update the ylim(bottom, top) values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline with SMOTE\n",
    "Used to over-sample the minority class (hate speech)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train_array = np.asarray(X_train)\n",
    "X_train_fix = np.reshape(X_train_array, (-1, 1))\n",
    "X_train_final = np.array(list(X_train_fix)).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_fix = np.reshape(y_train.values, (-1, 1))\n",
    "y_train_final = np.array(list(y_train_fix)).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "sm = SMOTE(random_state=35)\n",
    "smote_X_train, smote_y_train = sm.fit_resample(tfidf_data_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_logreg = LogisticRegression(penalty='l2', random_state=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "smote_logreg.fit(smote_X_train, smote_y_train)\n",
    "smote_logreg_test_preds = smote_logreg.predict(tfidf_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_precision = precision_score(y_test, smote_logreg_test_preds)\n",
    "smote_recall = recall_score(y_test, smote_logreg_test_preds)\n",
    "smote_f1_score = f1_score(y_test, smote_logreg_test_preds)\n",
    "smote_weighted_f1_score = f1_score(y_test, smote_logreg_test_preds, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Metrics for Oversampled Logistic Regression Baseline with Lemmatization Features\n",
      "Precision: 0.2363\n",
      "Recall: 0.5796\n",
      "F1 Score: 0.3358\n"
     ]
    }
   ],
   "source": [
    "# printing evaluation metrics up to 4th decimal place\n",
    "print('Testing Metrics for Oversampled Logistic Regression Baseline with Lemmatization Features')\n",
    "print('Precision: {:.4}'.format(smote_precision))\n",
    "print('Recall: {:.4}'.format(smote_recall))\n",
    "print('F1 Score: {:.4}'.format(smote_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_dict['Baseline Log Reg Oversampled with SMOTE'] = {'precision': smote_precision, 'recall': smote_recall, 'f1_score': smote_f1_score,  'weighted_f1': smote_weighted_f1_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline with Tomek Links\n",
    "Used to under-sample the majority class (not hate speech)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0: 37466, 1: 2564})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.under_sampling import TomekLinks # doctest: +NORMALIZE_WHITESPACE\n",
    "\n",
    "tl = TomekLinks()\n",
    "tomek_X_train, tomek_y_train = tl.fit_resample(tfidf_data_train, y_train)\n",
    "print('Resampled dataset shape %s' % Counter(tomek_y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It only removed 48((())) values from the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tomek_logreg = LogisticRegression(penalty='l2', random_state=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tomek_logreg.fit(tomek_X_train, tomek_y_train)\n",
    "tomek_logreg_test_preds = tomek_logreg.predict(tfidf_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tomek_precision = precision_score(y_test, tomek_logreg_test_preds)\n",
    "tomek_recall = recall_score(y_test, tomek_logreg_test_preds)\n",
    "tomek_f1_score = f1_score(y_test, tomek_logreg_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Metrics for Undersampled Logistic Regression Baseline with Lemmatization Features\n",
      "Precision: 0.3553\n",
      "Recall: 0.03982\n",
      "F1 Score: 0.07162\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# printing evaluation metrics up to 4th decimal place\n",
    "print('Testing Metrics for Undersampled Logistic Regression Baseline with Lemmatization Features')\n",
    "print('Precision: {:.4}'.format(tomek_precision))\n",
    "print('Recall: {:.4}'.format(tomek_recall))\n",
    "print('F1 Score: {:.4}'.format(tomek_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_dict['Baseline Log Reg Undersampled with Tomek Links'] = {'precision': tomek_precision, 'recall': tomek_recall, 'f1_score': tomek_f1_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for All Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>weighted_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline Logisitic Regression</th>\n",
       "      <td>0.219943</td>\n",
       "      <td>0.679941</td>\n",
       "      <td>0.332372</td>\n",
       "      <td>0.855050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Log Reg Oversampled with SMOTE</th>\n",
       "      <td>0.236320</td>\n",
       "      <td>0.579646</td>\n",
       "      <td>0.335754</td>\n",
       "      <td>0.873338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Log Reg Undersampled with Tomek Links</th>\n",
       "      <td>0.355263</td>\n",
       "      <td>0.039823</td>\n",
       "      <td>0.071618</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                precision    recall  f1_score  \\\n",
       "Baseline Logisitic Regression                    0.219943  0.679941  0.332372   \n",
       "Baseline Log Reg Oversampled with SMOTE          0.236320  0.579646  0.335754   \n",
       "Baseline Log Reg Undersampled with Tomek Links   0.355263  0.039823  0.071618   \n",
       "\n",
       "                                                weighted_f1  \n",
       "Baseline Logisitic Regression                      0.855050  \n",
       "Baseline Log Reg Oversampled with SMOTE            0.873338  \n",
       "Baseline Log Reg Undersampled with Tomek Links          NaN  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(metric_dict, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of all of them, **the baseline oversampled with SMOTE** performed the best. So let's run grid search on that one to find the optimal parameters.\n",
    "\n",
    "It's important to note that this model produces the same score as a baseline SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the model\n",
    "baseline_model = LogisticRegression(class_weight='balanced', random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating param_dict\n",
    "param_dict={'penalty': ['l1', 'l2'], 'solver': ['liblinear', 'newton-cg', 'sag'], 'C':\n",
    "[100, 10, 1.0, 0.1, 0.01]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate Grid Search CV with F1 metric\n",
    "grid_baseline = GridSearchCV(baseline_model, param_dict, cv=5, scoring='f1', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'tweet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15380/3827494344.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmy_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'tweet'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmy_float\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_float\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 👉️ 12.345\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'tweet'"
     ]
    }
   ],
   "source": [
    "my_str = 'tweet'\n",
    "\n",
    "my_float = float(my_str.replace(',', '').replace('%', ''))\n",
    "\n",
    "print(my_float)  # 👉️ 12.345\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "   #FROM ONLINE TO INCREASE NO. of Iteractions\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model=LogisticRegression(max_iter=3000)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'lying dont worship bab people worship people like raila uhuru known nyakundi list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15380/2721349307.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Ricky\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1136\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1138\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m   1139\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1140\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ricky\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    594\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    597\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ricky\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1072\u001b[0m         )\n\u001b[0;32m   1073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1074\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m   1075\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1076\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ricky\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    854\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 856\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    857\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m                 raise ValueError(\n",
      "\u001b[1;32mc:\\Users\\Ricky\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'lying dont worship bab people worship people like raila uhuru known nyakundi list'"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ricky\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# fit the grid search to our data\n",
    "grid_baseline.fit(tfidf_data_train, y_train)\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the response for test dataset\n",
    "grid_base_y_pred_train = grid_baseline.best_estimator_.predict(tfidf_data_train)\n",
    "\n",
    "# predict the training set\n",
    "grid_base_y_pred_test = grid_baseline.best_estimator_.predict(tfidf_data_test)\n",
    "\n",
    "# Model F1, how often is the classifier correct?\n",
    "print('Tuned Logistic Regression Model Predictions')\n",
    "print(\"F1 on train set:\",metrics.f1_score(y_train, grid_base_y_pred_train))\n",
    "print(\"F1 on test set:\",metrics.f1_score(y_test, grid_base_y_pred_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df5a47594a4c7fa77718041c239adbe925734d95d528854ea959dd8eef4ca91e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
